{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle > /dev/null\n",
    "!pip install torch torchvision > /dev/null\n",
    "!conda install -c conda-forge tpot -y > /dev/null\n",
    "!conda install -c conda-forge tpot xgboost dask dask-ml scikit-mdr skrebate -y > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_clean_train = pd.read_csv(\"./data/clean/train.csv\", index_col='PassengerId')\n",
    "pd_clean_test = pd.read_csv(\"./data/clean/test.csv\", index_col='PassengerId')\n",
    "pd_sample_submission = pd.read_csv(\"../input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 0 to 99999\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Survived     100000 non-null  int64  \n",
      " 1   Pclass       100000 non-null  int64  \n",
      " 2   Name         100000 non-null  object \n",
      " 3   Sex          100000 non-null  object \n",
      " 4   Age          96708 non-null   float64\n",
      " 5   SibSp        100000 non-null  int64  \n",
      " 6   Parch        100000 non-null  int64  \n",
      " 7   Ticket       95377 non-null   object \n",
      " 8   Fare         99866 non-null   float64\n",
      " 9   Cabin        32134 non-null   object \n",
      " 10  Embarked     99750 non-null   object \n",
      " 11  family       100000 non-null  int64  \n",
      " 12  ticket_type  24655 non-null   object \n",
      " 13  ticket_num   94704 non-null   float64\n",
      " 14  cabin_id     100000 non-null  object \n",
      " 15  surname      100000 non-null  object \n",
      " 16  age_bin      96708 non-null   float64\n",
      "dtypes: float64(4), int64(5), object(8)\n",
      "memory usage: 13.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family</th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>ticket_num</th>\n",
       "      <th>cabin_id</th>\n",
       "      <th>surname</th>\n",
       "      <th>age_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oconnor, Frankie</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209245</td>\n",
       "      <td>27.14</td>\n",
       "      <td>C12239</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209245.0</td>\n",
       "      <td>C</td>\n",
       "      <td>Oconnor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass              Name   Sex  Age  SibSp  Parch  \\\n",
       "PassengerId                                                                \n",
       "0                   1       1  Oconnor, Frankie  male  NaN      2      0   \n",
       "\n",
       "             Ticket   Fare   Cabin Embarked  family ticket_type  ticket_num  \\\n",
       "PassengerId                                                                   \n",
       "0            209245  27.14  C12239        S       2         NaN    209245.0   \n",
       "\n",
       "            cabin_id  surname  age_bin  \n",
       "PassengerId                             \n",
       "0                  C  Oconnor      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_clean_train.info()\n",
    "pd_clean_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(pd_df):\n",
    "    \"\"\"Fill missing age values with median value for each class\"\"\"\n",
    "    age_map = pd_df[['Age', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n",
    "    \n",
    "    return pd_df.assign(Age=pd_df['Age'].fillna(pd_df['Pclass'].map(age_map['Age'])))\n",
    "\n",
    "\n",
    "def impute_fare(pd_df):\n",
    "    \"\"\"Fill missing fare values with median value for each class\"\"\"\n",
    "    fare_map = pd_df[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n",
    "    \n",
    "    return pd_df.assign(Fare=pd_df['Fare'].fillna(pd_df['Pclass'].map(fare_map['Fare'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_clean_all = (pd.concat([pd_clean_train, pd_clean_test])\n",
    "    .pipe(impute_age)\n",
    "    .pipe(impute_fare))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Modeling Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(pd_df):\n",
    "    dataset_cols = [\n",
    "        'Sex',\n",
    "        'Embarked',\n",
    "        'Pclass',\n",
    "        'Age',\n",
    "        'SibSp',\n",
    "        'Parch',\n",
    "        'Fare',\n",
    "        'family',\n",
    "        'ticket_type',\n",
    "        'cabin_id',\n",
    "        'Survived']\n",
    "    \n",
    "    return pd_df.loc[:, [col for col in dataset_cols if col in pd_df.columns]]\n",
    "\n",
    "\n",
    "def one_hot_encode(pd_df):\n",
    "    pd_df = pd.get_dummies(pd_df, columns=['Sex', 'Embarked', 'ticket_type', 'cabin_id'], dummy_na=True)\n",
    "    pd_df = pd_df.drop('Sex_nan', axis=1)  # no null values exist in training or test set\n",
    "    \n",
    "    return pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_model_train = (pd_clean_all\n",
    "    .loc[:pd_clean_train.index.max()]\n",
    "    .pipe(format_dataset)\n",
    "    .pipe(one_hot_encode))\n",
    "pd_model_test = (pd_clean_test\n",
    "    .loc[pd_clean_test.index.min():]\n",
    "    .pipe(format_dataset)\n",
    "    .pipe(one_hot_encode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer = TPOTClassifier(\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    memory='auto',\n",
    "    max_time_mins=120,  # total time \n",
    "    max_eval_time_mins=20,  # max time per pipeline\n",
    "    population_size=40,\n",
    "    verbosity=3,\n",
    "    random_state=3,\n",
    "    warm_start=False,\n",
    "    log_file=\"./models/2.2-tpot-log.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d993c6309fd404e874a8c6682784d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=40.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_optimizer.fit(\n",
    "    features=pd_model_train.drop('Survived', axis=1), \n",
    "    target=pd_model_train.Survived,\n",
    "    groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write-out best pipeline\n",
    "pipeline_optimizer.export('./models/2.2-tpot_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline_optimizer.predict(pd_model_test)\n",
    "pd_submission = pd_sample_submission.drop('Survived', axis=1)\n",
    "pd_submission = pd_submission.assign(Survived=predictions)\n",
    "pd_submission.to_csv('./submissions/2.2-modelling-tpot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "100%|█████████████████████████████████████████| 879k/879k [00:01<00:00, 656kB/s]\n",
      "Successfully submitted to Tabular Playground Series - Apr 2021"
     ]
    }
   ],
   "source": [
    "# Submit\n",
    "!kaggle competitions submit -c tabular-playground-series-apr-2021 -f ./submissions/2.2-modelling-tpot.csv -m \"2.2-modellng-tpot\""
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
